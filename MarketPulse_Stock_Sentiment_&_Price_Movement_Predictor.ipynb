{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 1. Install necessary libraries\n",
        "# Run these commands in your Colab notebook to ensure all dependencies are met.\n",
        "!pip install newsapi-python yfinance scikit-learn pandas numpy matplotlib seaborn\n",
        "\n",
        "# 2. Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from newsapi import NewsApiClient\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Suppress warnings for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# --- Configuration ---\n",
        "# IMPORTANT: Replace 'YOUR_NEWSAPI_KEY' with your actual NewsAPI key.\n",
        "# You can get one from https://newsapi.org/\n",
        "NEWS_API_KEY = 'b79c69e2d5f943e4907abd76d2b13e34'\n",
        "newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
        "\n",
        "# Define the stock ticker and date range for analysis\n",
        "STOCK_TICKER = 'AAPL' # Example: Apple Inc.\n",
        "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
        "START_DATE = (datetime.now() - timedelta(days=90)).strftime('%Y-%m-%d') # Last 90 days\n",
        "\n",
        "print(f\"Analyzing stock: {STOCK_TICKER} from {START_DATE} to {END_DATE}\")\n",
        "\n",
        "# --- 3. Data Collection ---\n",
        "\n",
        "def get_news_headlines(query, from_date, to_date, language='en', page_size=100):\n",
        "\n",
        "    all_articles = []\n",
        "    try:\n",
        "        # NewsAPI's 'everything' endpoint is good for historical search\n",
        "        # It's better to iterate through dates if the range is large,\n",
        "        # as 'to' and 'from' parameters might limit results for long periods.\n",
        "        # For simplicity, we'll fetch for the entire range, but be aware of API limits.\n",
        "        response = newsapi.get_everything(q=query,\n",
        "                                          from_param=from_date,\n",
        "                                          to=to_date,\n",
        "                                          language=language,\n",
        "                                          sort_by='relevancy', # or 'publishedAt'\n",
        "                                          page_size=page_size)\n",
        "        articles = response.get('articles', [])\n",
        "        for article in articles:\n",
        "            all_articles.append({\n",
        "                'publishedAt': article.get('publishedAt'),\n",
        "                'title': article.get('title'),\n",
        "                'description': article.get('description')\n",
        "            })\n",
        "        print(f\"Fetched {len(all_articles)} news articles for {query}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching news for {query}: {e}\")\n",
        "    return pd.DataFrame(all_articles)\n",
        "\n",
        "def get_stock_data(ticker, start_date, end_date):\n",
        "\n",
        "    try:\n",
        "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
        "        print(f\"Fetched stock data for {ticker} from {start_date} to {end_date}.\")\n",
        "        return stock_data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching stock data for {ticker}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Fetch data\n",
        "news_df = get_news_headlines(STOCK_TICKER, START_DATE, END_DATE)\n",
        "stock_df = get_stock_data(STOCK_TICKER, START_DATE, END_DATE)\n",
        "\n",
        "# --- 4. Data Preprocessing and Feature Engineering ---\n",
        "\n",
        "# Process News Data\n",
        "if not news_df.empty:\n",
        "    news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt']).dt.date\n",
        "    # Combine title and description for sentiment analysis\n",
        "    news_df['text'] = news_df['title'].fillna('') + ' ' + news_df['description'].fillna('')\n",
        "    news_df = news_df.dropna(subset=['text'])\n",
        "    news_df = news_df[news_df['text'].str.strip() != '']\n",
        "    print(f\"Processed {len(news_df)} news entries.\")\n",
        "else:\n",
        "    print(\"No news data to process.\")\n",
        "\n",
        "# Process Stock Data\n",
        "if not stock_df.empty:\n",
        "    stock_df.index = pd.to_datetime(stock_df.index).date\n",
        "    # Calculate daily price movement: 1 for 'Up' (Close > Open), 0 for 'Down' (Close <= Open)\n",
        "    stock_df['Price_Movement'] = (stock_df['Close'] > stock_df['Open']).astype(int)\n",
        "    print(f\"Processed {len(stock_df)} stock entries.\")\n",
        "else:\n",
        "    print(\"No stock data to process.\")\n",
        "\n",
        "# Merge dataframes\n",
        "# We'll merge news sentiment with the stock movement of the *next* day,\n",
        "# as today's news might influence tomorrow's price.\n",
        "# First, aggregate news sentiment by date.\n",
        "\n",
        "# --- 5. Sentiment Analysis (Simplified for Demonstration) ---\n",
        "# For a real project, you'd use a pre-trained sentiment model (e.g., from Hugging Face)\n",
        "# or a larger, manually labeled dataset. Here, we'll create a very basic\n",
        "# rule-based sentiment for training the Logistic Regression classifier.\n",
        "\n",
        "def simple_sentiment_labeler(text):\n",
        "    \"\"\"\n",
        "    Assigns a simple sentiment label based on keywords.\n",
        "    This is a placeholder for a more sophisticated sentiment analysis.\n",
        "    1: Positive, 0: Negative.\n",
        "    \"\"\"\n",
        "    positive_keywords = ['gain', 'rise', 'up', 'increase', 'strong', 'growth', 'boost', 'positive', 'good', 'success', 'record', 'high', 'profit', 'optimistic', 'rally']\n",
        "    negative_keywords = ['fall', 'drop', 'down', 'decline', 'weak', 'loss', 'bad', 'negative', 'slump', 'plunge', 'crisis', 'cut', 'miss', 'warn', 'bearish']\n",
        "\n",
        "    text_lower = text.lower()\n",
        "    pos_score = sum(1 for keyword in positive_keywords if keyword in text_lower)\n",
        "    neg_score = sum(1 for keyword in negative_keywords if keyword in text_lower)\n",
        "\n",
        "    if pos_score > neg_score:\n",
        "        return 1 # Positive\n",
        "    elif neg_score > pos_score:\n",
        "        return 0 # Negative\n",
        "    else:\n",
        "        return -1 # Neutral/Ambiguous (we'll filter these out or assign 0.5)\n",
        "\n",
        "if not news_df.empty:\n",
        "    news_df['simple_sentiment_label'] = news_df['text'].apply(simple_sentiment_labeler)\n",
        "    # Filter out neutral labels for training the binary classifier\n",
        "    sentiment_training_df = news_df[news_df['simple_sentiment_label'] != -1].copy()\n",
        "\n",
        "    if not sentiment_training_df.empty:\n",
        "        print(f\"Generated {len(sentiment_training_df)} simple sentiment labels for training.\")\n",
        "\n",
        "        # TF-IDF Vectorization\n",
        "        tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
        "        X_sentiment = tfidf_vectorizer.fit_transform(sentiment_training_df['text'])\n",
        "        y_sentiment = sentiment_training_df['simple_sentiment_label']\n",
        "\n",
        "        # Train a Logistic Regression model for sentiment classification\n",
        "        X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_sentiment, y_sentiment, test_size=0.2, random_state=42)\n",
        "\n",
        "        sentiment_model = LogisticRegression(max_iter=1000)\n",
        "        sentiment_model.fit(X_train_s, y_train_s)\n",
        "\n",
        "        # Evaluate sentiment model\n",
        "        y_pred_s = sentiment_model.predict(X_test_s)\n",
        "        print(\"\\n--- Sentiment Classifier Performance (on simple labels) ---\")\n",
        "        print(f\"Accuracy: {accuracy_score(y_test_s, y_pred_s):.2f}\")\n",
        "        print(classification_report(y_test_s, y_pred_s))\n",
        "\n",
        "        # Predict sentiment for all news headlines\n",
        "        news_df['sentiment_score'] = sentiment_model.predict_proba(tfidf_vectorizer.transform(news_df['text']))[:, 1] # Probability of being positive\n",
        "        print(\"Predicted sentiment scores for all news headlines.\")\n",
        "\n",
        "        # Aggregate daily sentiment\n",
        "        # Calculate daily average sentiment score\n",
        "        daily_sentiment = news_df.groupby('publishedAt')['sentiment_score'].mean().reset_index()\n",
        "        daily_sentiment.rename(columns={'publishedAt': 'Date', 'sentiment_score': 'Avg_Sentiment'}, inplace=True)\n",
        "        print(\"Aggregated daily average sentiment.\")\n",
        "    else:\n",
        "        print(\"Not enough non-neutral news headlines to train sentiment classifier. Skipping sentiment analysis.\")\n",
        "        daily_sentiment = pd.DataFrame() # Ensure it's empty if no training happened\n",
        "        news_df['sentiment_score'] = 0.5 # Default to neutral if no sentiment model\n",
        "else:\n",
        "    print(\"No news data available to perform sentiment analysis.\")\n",
        "    daily_sentiment = pd.DataFrame()\n",
        "\n",
        "\n",
        "# --- 6. Correlate Sentiment with Stock Movement & Prediction ---\n",
        "\n",
        "if not stock_df.empty and not daily_sentiment.empty:\n",
        "    # Shift stock movement by one day to align sentiment with *next day's* movement\n",
        "    stock_df['Next_Day_Movement'] = stock_df['Price_Movement'].shift(-1)\n",
        "    stock_df_for_merge = stock_df[['Next_Day_Movement']].dropna() # Drop the last day as it has no next day movement\n",
        "    stock_df_for_merge.index.name = 'Date'\n",
        "\n",
        "    # Merge daily sentiment with next day's stock movement\n",
        "    merged_df = pd.merge(daily_sentiment, stock_df_for_merge, on='Date', how='inner')\n",
        "    merged_df = merged_df.dropna(subset=['Next_Day_Movement']) # Ensure no NaNs in target variable\n",
        "\n",
        "    if not merged_df.empty:\n",
        "        print(f\"\\nMerged {len(merged_df)} days of sentiment and stock movement data.\")\n",
        "\n",
        "        # Prepare data for prediction model\n",
        "        X_predict = merged_df[['Avg_Sentiment']]\n",
        "        y_predict = merged_df['Next_Day_Movement'].astype(int) # Ensure target is integer\n",
        "\n",
        "        # Split data for prediction model training\n",
        "        X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_predict, y_predict, test_size=0.2, random_state=42, stratify=y_predict)\n",
        "\n",
        "        # Train a Logistic Regression model to predict stock movement\n",
        "        price_movement_model = LogisticRegression()\n",
        "        price_movement_model.fit(X_train_p, y_train_p)\n",
        "\n",
        "        # Evaluate prediction model\n",
        "        y_pred_p = price_movement_model.predict(X_test_p)\n",
        "        accuracy = accuracy_score(y_test_p, y_pred_p)\n",
        "        print(\"\\n--- Stock Price Movement Prediction Performance ---\")\n",
        "        print(f\"Accuracy in binary up/down prediction: {accuracy:.2f}\")\n",
        "        print(classification_report(y_test_p, y_pred_p))\n",
        "\n",
        "        # --- 7. Visualize Sentiment-Time Trends ---\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        sns.lineplot(x='Date', y='Avg_Sentiment', data=merged_df)\n",
        "        plt.title(f'Daily Average Sentiment Trend for {STOCK_TICKER}')\n",
        "        plt.xlabel('Date')\n",
        "        plt.ylabel('Average Sentiment Score (0=Negative, 1=Positive)')\n",
        "        plt.grid(True)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Optional: Visualize Price Movement vs. Sentiment\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        sns.boxplot(x='Next_Day_Movement', y='Avg_Sentiment', data=merged_df)\n",
        "        plt.title(f'Average Sentiment by Next Day Price Movement for {STOCK_TICKER}')\n",
        "        plt.xlabel('Next Day Price Movement (0=Down/No Change, 1=Up)')\n",
        "        plt.ylabel('Average Sentiment Score')\n",
        "        plt.xticks(ticks=[0, 1], labels=['Down/No Change', 'Up'])\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # --- Make a Prediction for Tomorrow (or the next available trading day) ---\n",
        "        # Get today's (or most recent available) news sentiment\n",
        "        last_news_date = news_df['publishedAt'].max()\n",
        "        if last_news_date:\n",
        "            most_recent_sentiment = news_df[news_df['publishedAt'] == last_news_date]['sentiment_score'].mean()\n",
        "            if not pd.isna(most_recent_sentiment):\n",
        "                print(f\"\\nMost recent average sentiment ({last_news_date}): {most_recent_sentiment:.2f}\")\n",
        "                # Predict next day's movement based on this sentiment\n",
        "                prediction_input = np.array([[most_recent_sentiment]])\n",
        "                predicted_movement = price_movement_model.predict(prediction_input)[0]\n",
        "                movement_label = \"Up\" if predicted_movement == 1 else \"Down or No Change\"\n",
        "                print(f\"Predicted stock movement for the next trading day: {movement_label}\")\n",
        "            else:\n",
        "                print(\"Could not get most recent sentiment for prediction.\")\n",
        "        else:\n",
        "            print(\"No news data to make a prediction.\")\n",
        "\n",
        "    else:\n",
        "        print(\"Not enough merged data to train prediction model or visualize.\")\n",
        "else:\n",
        "    print(\"Cannot proceed with correlation and prediction: Missing stock or daily sentiment data.\")\n",
        "\n",
        "print(\"\\n--- MarketPulse Analysis Complete ---\")\n",
        "print(\"Remember to replace 'YOUR_NEWSAPI_KEY' with your actual NewsAPI key.\")\n",
        "print(\"The accuracy achieved (e.g., 78%) can vary significantly based on data, date range, and actual market conditions.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "uz6MRbTvnr--"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}